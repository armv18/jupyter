{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa83ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install heuristicsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff9a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heuristicsearch.a_star_search import AStar\n",
    "\n",
    "aj_list = {\n",
    "    'A': [('B', 6), ('F', 3)],\n",
    "    'B': [('C', 3), ('D', 2)],\n",
    "    'C': [('D', 1), ('E', 5)],\n",
    "    'D': [('C', 1), ('E', 8)],\n",
    "    'E': [('I', 5), ('J', 5)],\n",
    "    'F': [('G', 1), ('H', 7)],\n",
    "    'G': [('I', 3)],\n",
    "    'H': [('I', 2)],\n",
    "    'I': [('E', 5), ('J', 3)],\n",
    "}\n",
    "\n",
    "heuristics = {'A': 10, 'B': 8, 'C': 5, 'D': 7, 'E': 3, 'F': 6, 'G': 5, 'H': 3, 'I': 1, 'J': 0}\n",
    "\n",
    "graph = AStar(aj_list, heuristics)\n",
    "\n",
    "graph.apply_a_star(start='A', stop='J')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085a5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heuristicsearch.ao_star import AOStar\n",
    "\n",
    "print(\"Graphs-1\")\n",
    "\n",
    "heuristic = {'A': 1, 'B': 6, 'C': 2, 'D': 12, 'E': 2, 'G': 1, 'H': 7, 'J': 1, 'T': 3}\n",
    "\n",
    "aj_list = {\n",
    "    'A': [[('B', 1), ('C', 1)], [('D', 1)]],\n",
    "    'B': [[('G', 1)], [('H', 1)]],\n",
    "    'C': [[('J', 1)]],\n",
    "    'D': [[('E', 1), ('F', 1)]],\n",
    "    'G': [[('I', 1)]]\n",
    "}\n",
    "\n",
    "graph = AOStar(aj_list, heuristic, 'A')\n",
    "\n",
    "graph.applyAOStar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b71d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Regression Algorithm\n",
    "import numpy as np\n",
    "\n",
    "inputNeurons=2\n",
    "\n",
    "hiddenlayerNeurons=2\n",
    "\n",
    "outputNeurons=2\n",
    "\n",
    "\n",
    "\n",
    "input = np.random.randint(1,100,inputNeurons)\n",
    "\n",
    "output = np.array([5.0,10.0])\n",
    "\n",
    "hidden_layer=np.random.rand(1,hiddenlayerNeurons)\n",
    "\n",
    "\n",
    "\n",
    "hidden_biass=np.random.rand(1,hiddenlayerNeurons)\n",
    "\n",
    "output_bias=np.random.rand(1,outputNeurons)\n",
    "\n",
    "hidden_weights=np.random.rand(inputNeurons,hiddenlayerNeurons)\n",
    "\n",
    "output_weights=np.random.rand(hiddenlayerNeurons,outputNeurons)\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid (layer):\n",
    "\n",
    "        return 1/(1 + np.exp(-layer))\n",
    "\n",
    "\n",
    "\n",
    "def gradient(layer):\n",
    "\n",
    "       return layer*(1-layer)\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "       hidden_layer=np.dot(input,hidden_weights)\n",
    "\n",
    "       hidden_layer=sigmoid(hidden_layer+hidden_biass)\n",
    "\n",
    "       output_layer=np.dot(hidden_layer,output_weights)\n",
    "\n",
    "       output_layer=sigmoid(output_layer+output_bias)\n",
    "\n",
    "       error = (output-output_layer)\n",
    "       gradient_outputLayer=gradient(output_layer)\n",
    "\n",
    "       error_terms_output=gradient_outputLayer * error\n",
    "\n",
    "       error_terms_hidden=gradient(hidden_layer)*np.dot(error_terms_output,output_weights.T)\n",
    "\n",
    "       gradient_hidden_weights = np.dot(input.reshape(inputNeurons,1),error_terms_hidden.reshape(1,hiddenlayerNeurons))\n",
    "\n",
    "       gradient_ouput_weights = np.dot(hidden_layer.reshape(hiddenlayerNeurons,1),error_terms_output.reshape(1,outputNeurons))\n",
    "\n",
    "       hidden_weights = hidden_weights + 0.05*gradient_hidden_weights\n",
    "       output_weights = output_weights + 0.05*gradient_ouput_weights\n",
    "       print(\"**********************\")\n",
    "       print(\"iteration:\",i,\"::::\",error)\n",
    "       print(\"#####output######\",output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58eeb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#id3\n",
    "import math\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "def entropy(probs):\n",
    "      return sum([-prob * math.log(prob, 2) for prob in probs])\n",
    "    \n",
    "def entropy_list(a_list):\n",
    "     cnt = Counter(x for x in a_list)\n",
    "     num_instance = len(a_list) * 1.0\n",
    "     probs = [x / num_instance for x in cnt.values()]\n",
    "     return entropy(probs)\n",
    "\n",
    "def info_gain(df, split, target, trace=0):\n",
    "     df_split = df.groupby(split)\n",
    "     nobs = len(df.index) * 1.0\n",
    "     df_agg_ent = df_split.agg({target: [entropy_list, lambda x: len(x) / nobs]})\n",
    "     df_agg_ent.columns = [\"entropy\", \"propObserved\"]\n",
    "     new_entropy = sum(df_agg_ent[\"entropy\"] * df_agg_ent[\"propObserved\"])\n",
    "     old_entropy = entropy_list(df[target])\n",
    "     return old_entropy - new_entropy\n",
    "    \n",
    "def id3(df, target, attribute_name, default_class=None):\n",
    "     cnt = Counter(x for x in df[target])\n",
    "     if len(cnt) == 1:\n",
    "          return next(iter(cnt))\n",
    "     elif df.empty or (not attribute_name):\n",
    "         return default_class\n",
    "     else:\n",
    "         default_class = max(cnt.keys())\n",
    "         gains = [info_gain(df, attr, target) for attr in attribute_name]\n",
    "         index_max = gains.index(max(gains))\n",
    "         best_attr = attribute_name[index_max]\n",
    "         tree = {best_attr: {}}\n",
    "         remaining_attr = [x for x in attribute_name if x != best_attr]\n",
    "         for attr_val, data_subset in df.groupby(best_attr):\n",
    "               subtree = id3(data_subset, target, remaining_attr, default_class)\n",
    "               tree[best_attr][attr_val] = subtree\n",
    "         return tree\n",
    "    \n",
    "def classify(instance, tree, default=None):\n",
    "       attribute = next(iter(tree))\n",
    "       if instance[attribute] in tree[attribute].keys():\n",
    "            result = tree[attribute][instance[attribute]]\n",
    "            if isinstance(result, dict):\n",
    "                  return classify(instance, result)\n",
    "            else:\n",
    "                   return result\n",
    "       else:\n",
    "            return default\n",
    "        \n",
    "df_tennis = pd.read_csv('playtennis.csv')\n",
    "print(df_tennis)\n",
    "attribute_names = list(df_tennis.columns)\n",
    "attribute_names.remove('PlayTennis')\n",
    "tree = id3(df_tennis, 'PlayTennis', attribute_names)\n",
    "print('\\n\\n The resultant decision tree is: \\n\\n')\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d69fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#                Na√Øve Bayes Classifier\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "data = pd.read_csv('id3.csv')\n",
    "print(\"The first 5 Values of data is :\\n\", data.head())\n",
    "X = data.iloc[:, :-1]\n",
    "print(\"\\nThe First 5 values of the train data is\\n\", X.head())\n",
    "y = data.iloc[:, -1]\n",
    "print(\"\\nThe First 5 values of train output is\\n\", y.head())\n",
    "le_outlook = LabelEncoder()\n",
    "X.Outlook = le_outlook.fit_transform(X.Outlook)\n",
    "le_Temperature = LabelEncoder()\n",
    "X.Temperature = le_Temperature.fit_transform(X.Temperature)\n",
    "le_Humidity = LabelEncoder()\n",
    "X.Humidity = le_Humidity.fit_transform(X.Humidity)\n",
    "le_Wind = LabelEncoder()\n",
    "X.Wind = le_Wind.fit_transform(X.Wind)\n",
    "print(\"\\nNow the Train output is\\n\", X.head())\n",
    "le_PlayTennis = LabelEncoder()\n",
    "y = le_PlayTennis.fit_transform(y)\n",
    "print(\"\\nNow the Train output is\\n\",y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "predictTestData = classifier.predict([[1, 0, 1, 0]])\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy is:\", accuracy_score(classifier.predict(X_test), y_test))\n",
    "print(\"Predicted Value for individual Test Data:\", predictTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cc8298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means & EM Algorithm\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "print(iris)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(iris.data,iris.target)\n",
    "\n",
    "model =KMeans(n_clusters=3)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "model.score\n",
    "\n",
    "print('K-Mean: ',metrics.accuracy_score(y_test,model.predict(X_test)))\n",
    "#-------Expectation and Maximization----------\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "model2 = GaussianMixture(n_components=3)\n",
    "\n",
    "model2.fit(X_train,y_train)\n",
    "\n",
    "model2.score\n",
    "\n",
    "print('EM Algorithm:',metrics.accuracy_score(y_test,model2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     KNN Algorithm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "\n",
    "print(\"Iris Data set loaded...\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data,iris.target,test_size=0.1)\n",
    "\n",
    "#random_state=0\n",
    "\n",
    "for i in range(len(iris.target_names)):\n",
    "\n",
    "     print(\"Label\", i , \"-\",str(iris.target_names[i]))\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred=classifier.predict(x_test)\n",
    "\n",
    "print(\"Results of Classification using K-nn with K=5 \")\n",
    "\n",
    "for r in range(0,len(x_test)):\n",
    "\n",
    "      print(\" Sample:\", str(x_test[r]), \" Actual-label:\", str(y_test[r]),\" Predicted-label:\", str(y_pred[r]))\n",
    "\n",
    "      print(\"Classification Accuracy :\" , classifier.score(x_test,y_test));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regression Algorithmimport numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "y = np.log(np.abs((x ** 2) - 1) + 0.5)\n",
    "x = x + np.random.normal(scale=0.05, size=1000)\n",
    "plt.scatter(x, y, alpha=0.3)\n",
    "\n",
    "def local_regression(x0, x, y, tau):\n",
    "    x0 = np.r_[1, x0]\n",
    "    x = np.c_[np.ones(len(x)), x]\n",
    "    xw = x.T * radial_kernel(x0, x, tau)\n",
    "    beta = np.linalg.pinv(xw @ x) @ xw @ y\n",
    "    return x0 @ beta\n",
    "\n",
    "def radial_kernel(x0, x, tau):\n",
    "    return np.exp(np.sum((x - x0) ** 2, axis=1) / (-2 * tau ** 2))\n",
    "\n",
    "def plot_lr(tau):\n",
    "    domain = np.linspace(-5, 5, num=500)\n",
    "    pred = [local_regression(x0, x, y, tau) for x0 in domain]\n",
    "    plt.scatter(x, y, alpha=0.3)\n",
    "    plt.plot(domain, pred, color=\"red\")\n",
    "    plt.show()\n",
    "\n",
    "plot_lr(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3254097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Candidate Elimination Algorithm for EnjoySport\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('playtennis.csv')\n",
    "\n",
    "concepts = np.array(data.iloc[:, 0:-1])\n",
    "print(concepts)\n",
    "\n",
    "target = np.array(data.iloc[:, -1])\n",
    "print(target)\n",
    "\n",
    "def learn(concepts, target):\n",
    "    specific_h = concepts[0].copy()\n",
    "    print('Initialization of specific_h and general_h')\n",
    "    print(specific_h)\n",
    "\n",
    "    general_h = [['?' for i in range(len(specific_h))] for j in range(len(specific_h))]\n",
    "    print(general_h)\n",
    "\n",
    "    for i, h in enumerate(concepts):\n",
    "        if target[i] == 'yes':\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x] != specific_h[x]:\n",
    "                    specific_h[x] = '?'\n",
    "                    general_h[x][x] = '?'\n",
    "        elif target[i] == 'no':\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x] != specific_h[x]:\n",
    "                    general_h[x][x] = specific_h[x]\n",
    "                else:\n",
    "                    general_h[x][x] = '?'\n",
    "\n",
    "        print(f'Steps of Candidate Elimination Algorithm {i + 1}')\n",
    "        print('Specific_h:', specific_h)\n",
    "        print('General_h:', general_h)\n",
    "\n",
    "    indices = [i for i, val in enumerate(general_h) if val == ['?' for _ in range(len(specific_h))]]\n",
    "\n",
    "    for i in indices:\n",
    "        general_h.remove(['?' for _ in range(len(specific_h))])\n",
    "\n",
    "    return specific_h, general_h\n",
    "\n",
    "s_final, g_final = learn(concepts, target)\n",
    "\n",
    "print('----------------Final Answer----------------\\n')\n",
    "print('Final specific_h:\\n', s_final)\n",
    "print('Final general_h:\\n', g_final)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
